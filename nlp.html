<!DOCTYPE html>
<html lang=en>
  <head>
    <title>Natural Language Processing</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="extraStyles.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
  </head>
  <body class="bg-portfolio">
    <div class="container bg-navbar rounded">
      <nav class="navbar navbar-expand-lg bg-navbar">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item">
            <a class="navbar-brand nav-link" href="engineering-honors.html">EHP Portfolio</a>
          </li>
          <li class="nav-item">
            <a href="philosophy-of-ed.html" class="nav-link">Philosophy of Education</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Works
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="catfund.html">Catfund</a>
              <a class="dropdown-item" href="risk-project.html">Risk Research</a>
            </div>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              Classwork
            </a>
            <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="dropdown-item disabled" href="#">ML/Data Science</a>
              <a class="dropdown-item" href="nlp.html">Natural Language Processing</a>
              <a class="dropdown-item" href="clustering.html">Reddit Event Clustering</a>
              <div class="dropdown-divider"></div>
              <a class="dropdown-item disabled" href="#">Writings</a>
              <a class="dropdown-item" href="resources/canvas-report.pdf">Canvas Consulting Report</a>
              <a class="dropdown-item" href="resources/state-of-ai.pdf">Human and Machine Problem-solving</a>
              <div class="dropdown-divider"></div>
              <a class="dropdown-item disabled" href="#">Musical Undertakings</a>
              <a class="dropdown-item" href="sunken-cathedral.html">The Sunken Cathedral</a>
              <a class="dropdown-item" href="out-like-a-light.html">Out Like a Light</a>
            </div>
          </li>
          <li class="nav-item">
            <a href="brussels.html" class="nav-link">Abroad in Brussels</a>
          </li>
          <li class="nav-item">
            <a href="resources/Resume.pdf" class="nav-link">Resume</a>
          </li>
        </ul>
      </nav>
    </div>
    <div class="container bg-light rounded">
      <div class="card-body">
        <div class="py-4">
          <h1>Natural Language Processing</h1>
          <h4><i>As it turns out, language is complicated</i></h4>
        </div>
        <div>
          <p>
            Natural language processing - language-related AI - is one of my biggest passions. 
            I've enjoyed learning languages (or attempting to) for most of my life - something 
            about the structures and little quirks has always delighted me. Naturally, I 
            tremendously enjoy the opportunity to combine this with my passion for AI and making
            machines that seem to think.
          </p>
          <p>
            In the course of CU's NLP class, I had the opportunity to work on one of the standard
            NLP evaluation tasks, the Choice of Plausible Alternatives (COPA) task. This task
            is intended to test how well an AI system can understand logical entailment. The idea is 
            to provide an AI model with three sentences: one "premise", and two alternative "hypotheses".
            The model's task is to figure out which hypothesis logically follows the premise. The 
            general theory is that logic is a tougher linguistic task than something like determining
            what part of speech a word is; to perform logic, the model needs to know something about the
            world at large, to understand <i>concepts</i> rather than just letters and words.
          </p>
          <p>
            As far as the technical details go, we used the PyTorch, Transformers, and Pandas Python 
            libraries to fine-tune pretrained embedding models (RoBERTa and DeBERTa) on data 
            particular to this task. The end performance our models achieved wasn't stellar, but it
            gave us the opportunity to learn a <i>lot</i> about using these sorts of models. A big part
            of the process was learning to use GPU acceleration via CUDA - we hypothesized that one of
            the main blockers for our training was not being able to fit a large enough training batch size
            on our single GPUs. According to some of the research we did, batch size matters a lot when
            training transformer-based models like the ones we used.
          </p>
          <p>
            (For the less technical - we essentially borrowed AI systems that other academics had trained
            on huge datasets, which gave them a nebulous understanding of English. We then used a smaller
            number of examples of the task that we wanted performed, hoping that their general understanding
            of English would let them learn the COPA task faster.)
          </p>
          <p>
            A post-GPT-4 update: this task is, to a large degree, solved now; large language models
            like PaLM 540B are able to achieve <a href="https://paperswithcode.com/sota/question-answering-on-copa">100% accuracy</a> 
            when fine-tuned on this task. We knew when we attempted it that large pretrained models were
            something special (the first paper to indicate that, Brown et al.'s <i>Language Models are Few-Shot Learners</i>,
            had been out for a year at this point), but we had no idea how important they would become.
            Such is life, I suppose.
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
